{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, run the code in extract_precision_matrices.ipynb to obtain precision matrices: FCprec_concat_allsub.mat\n",
    "# Then, run unpack_precision_mats to split FCprec_concat_allsub.mat into single subject .mat files\n",
    "\n",
    "cwd='/Users/emilyolafson/GIT/stroke-graph-matching/data/'\n",
    "unpack_precision_mats(cwd)\n",
    "\n",
    "# After unpack_precision_mats is run, format precision data:\n",
    "# - Set diagonals of precision FC to 0.\n",
    "# - create a .mat file that contains precision FCs in a cell array. Subjects in rows & longitudinal time points in columns.\n",
    "\n",
    "# MATLAB code for formatting this dataset: format_precision.m\n",
    "\n",
    "# Then, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_precision_mats(cwd):\n",
    "    \"\"\"Turn concatenated precision FC matrix into multiple single subject/single session matrices.\n",
    "    Save each single suject to /precision/ folder.\"\"\"\n",
    "    data_dir = str(cwd) \n",
    "    subj_all = np.genfromtxt(data_dir + 'precision/subjects.txt', dtype = 'str') #list of subjects in same order as precision matrices are saved.    \n",
    "    fc_dir = data_dir + 'precision/'\n",
    "    output_prec = sio.loadmat(fc_dir + 'FCprec_concat_allsub.mat')\n",
    "    prec = output_prec['C'] \n",
    "    c = 0\n",
    "    for sub in subj_all:\n",
    "        mdic = {\"C\": prec[c]}\n",
    "        sio.savemat(fc_dir + sub, mdic)\n",
    "        c=c+1\n",
    "        \n",
    "def remap_cost_regularized(interval, fc, alpha, beta):\n",
    "    \"\"\"Cost function: the cost of remapping each node in matrix A to every other node in matrix B. \n",
    "    Output is fed into graph matching algorithm. Regularization: (costmatrix - alpha*I) \n",
    "    where alpha is a regularization parameter controlling the degree to which a remapping\n",
    "    to itself is preferred over remapping to any other node.\"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    data_dir = '/Users/emilyolafson/GIT/stroke-graph-matching/data'\n",
    "    distances=sio.loadmat(data_dir + '/pairwise_eucl_dist_shen268.mat')\n",
    "\n",
    "    distances=distances['eucl_dist']\n",
    "    costmat_all=list()\n",
    "\n",
    "    nROIs=fc[0][0].shape[0]\n",
    "    \n",
    "    #calculate cost between all ROIs\n",
    "    for i in range(0,fc.shape[0]): #subject \n",
    "\n",
    "        if (dx == 'stroke' and i==5 and interval == [3,4]): #sub6 has no 4,5\n",
    "            continue \n",
    "        if (dx == 'stroke' and i==11 and (interval == [3,4] or interval == [2,3])): #sub12 has no 4,5 OR 3,4\n",
    "            continue\n",
    "        if (dx == 'stroke' and i==19 and (interval == [3,4] or interval == [2,3] or interval == [1,2])): #sub20 has no 4,5 OR 3,4 OR 2,3\n",
    "            continue\n",
    "            \n",
    "        costmat=np.zeros((nROIs,nROIs))\n",
    "\n",
    "        for x in range(0,nROIs): #x = time point 1.\n",
    "            a=fc[i,interval[0]][x]\n",
    "\n",
    "            for y in range(0,nROIs): #y = time point 2.\n",
    "                b=fc[i,interval[1]][y]\n",
    "                \n",
    "                costmat[x,y]=distance.euclidean(a,b)\n",
    "                \n",
    "        costmat=costmat+beta*distances\n",
    "        costmat_all.append(costmat)\n",
    "\n",
    "    return [costmat_all, nROIs]\n",
    "\n",
    "def graph_matching_regularized(costmat_all, interval, nROIs, dx, alpha, alphacounter, beta, betacounter):\n",
    "    \"\"\"Runs graph matching w/ the Hungarian algorithm and saves outputs:\n",
    "    \n",
    "        cols_SXSY.txt - each row is a different subject. Values in each column represent the node\n",
    "        in the latter time point that the node in the prior time point was mapped to.\n",
    "        \n",
    "        roichanges_SXSY.txt - each row is a different subject. Values in each column represent \n",
    "        whether the node was remapped to a DIFFERENT node than itself in the subsequent time point \n",
    "        (elements are 0 or 1, 1 if the node was remapped to a different node and 0 if the node was mapped to itself.\n",
    "        Used to calculate remap frequency for each region, when averaged vertically (across subjects).\"\"\"\n",
    "    \n",
    "    results_dir = '/Users/emilyolafson/GIT/stroke-graph-matching/project/results/'\n",
    "    print(alphacounter)\n",
    "    nROIs=fc[0][0].shape[0]\n",
    "    nsubs=len(costmat_all) #test\n",
    "    \n",
    "    rows=np.zeros((nsubs,nROIs))\n",
    "    cols=np.zeros((nsubs,nROIs))\n",
    "    roichanges=np.zeros((nsubs,nROIs))\n",
    "    truecols=range(0,nROIs)\n",
    "\n",
    "    for i in range(0, nsubs):\n",
    "        cost=costmat_all[i]\n",
    "        rowind, colind=linear_sum_assignment(cost) #graph matching part.\n",
    "        rows[i]=rowind\n",
    "        cols[i]=colind\n",
    "\n",
    "    np.savetxt(results_dir+'/precision/cols_'+ 'S'+str(interval[0]+1)+'S'+ str(interval[1]+1)+'_alpha' + str(alphacounter)+'_beta' + str(betacounter) + '.txt', cols)\n",
    "\n",
    "    for j in range(0,nsubs):\n",
    "        for i in range(0,nROIs):\n",
    "            if cols[j][i]!=truecols[i]:\n",
    "                roichanges[j][i]=1 #indices that are switched\n",
    "\n",
    "    allchanges=np.mean(roichanges,0)\n",
    "    np.savetxt(results_dir +'/precision/roichanges_' + 'S'+str(interval[0]+1)+'S'+ str(interval[1]+1) +'_alpha' + str(alphacounter)+'_beta' + str(betacounter) +'.txt', allchanges)\n",
    "    return [allchanges]\n",
    "\n",
    "def run_graph_matching_reg(interval, fc, dx, alpha,alphacounter, beta, betacounter):\n",
    "    \"\"\"Calculate the cost of remapping across all subjects, and perform graph matching.\n",
    "    Saves outputs to /results/jupyter/.../stroke and /controls.\"\"\"\n",
    "    [costmat_all, nROIs]=remap_cost_regularized(interval, fc, alpha, beta)\n",
    "    nswaps=graph_matching_regularized(costmat_all, interval, nROIs, dx, alpha,alphacounter, beta, betacounter)\n",
    "    return nswaps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing beta: 0\n",
      "0\n",
      "Mean num. swaps: 0.22907203114860478\n",
      "Testing beta: 0.0001\n",
      "0\n",
      "Mean num. swaps: 0.03780012978585334\n",
      "Testing beta: 0.0002\n",
      "0\n",
      "Mean num. swaps: 0.021576898118105127\n",
      "Testing beta: 0.0003\n",
      "0\n",
      "Mean num. swaps: 0.013951979234263464\n",
      "Testing beta: 0.0004\n",
      "0\n",
      "Mean num. swaps: 0.011680726800778715\n",
      "Testing beta: 0\n",
      "0\n",
      "Mean num. swaps: 0.2189620081411126\n",
      "Testing beta: 0.0001\n",
      "0\n",
      "Mean num. swaps: 0.033412483039348705\n",
      "Testing beta: 0.0002\n",
      "0\n",
      "Mean num. swaps: 0.016791044776119403\n",
      "Testing beta: 0.0003\n",
      "0\n",
      "Mean num. swaps: 0.010006784260515603\n",
      "Testing beta: 0.0004\n",
      "0\n",
      "Mean num. swaps: 0.007293080054274084\n",
      "Testing beta: 0\n",
      "0\n",
      "Mean num. swaps: 0.224591329068941\n",
      "Testing beta: 0.0001\n",
      "0\n",
      "Mean num. swaps: 0.0374911158493248\n",
      "Testing beta: 0.0002\n",
      "0\n",
      "Mean num. swaps: 0.022388059701492536\n",
      "Testing beta: 0.0003\n",
      "0\n",
      "Mean num. swaps: 0.01634683724235963\n",
      "Testing beta: 0.0004\n",
      "0\n",
      "Mean num. swaps: 0.011194029850746268\n",
      "Testing beta: 0\n",
      "0\n",
      "Mean num. swaps: 0.18302238805970147\n",
      "Testing beta: 0.0001\n",
      "0\n",
      "Mean num. swaps: 0.0330223880597015\n",
      "Testing beta: 0.0002\n",
      "0\n",
      "Mean num. swaps: 0.018656716417910446\n",
      "Testing beta: 0.0003\n",
      "0\n",
      "Mean num. swaps: 0.013992537313432836\n",
      "Testing beta: 0.0004\n",
      "0\n",
      "Mean num. swaps: 0.00951492537313433\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = '/Users/emilyolafson/GIT/stroke-graph-matching/data'\n",
    "fc_dir =data_dir + '/precision'\n",
    "fc=sio.loadmat(fc_dir + '/C_precision.mat')\n",
    "\n",
    "fc=fc['C_precision']\n",
    "intervals=[[0, 1], [1, 2], [2, 3], [3, 4]] #time point comparisons. 0=1, 1=2, etc.\n",
    "alpha=0\n",
    "session_swaps=list()\n",
    "for i in range(0, 4):\n",
    "    allswaps=list()\n",
    "    betas=[0, 0.0001, 0.0002, 0.0003, 0.0004]\n",
    "    betacounter = -1\n",
    "    alphacounter = 0\n",
    "    for beta in betas:\n",
    "        betacounter = betacounter +1\n",
    "        print('Testing beta: ' + str(beta))\n",
    "        nswaps=run_graph_matching_reg(intervals[i], fc, dx, alpha, alphacounter, beta, betacounter)\n",
    "        print('Mean num. swaps: ' + str(np.mean(nswaps)))\n",
    "        allswaps.append(nswaps)\n",
    "\n",
    "    \n",
    "    session_swaps.append(allswaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd='/Users/emilyolafson/GIT/stroke-graph-matching'\n",
    "data_dir = str(cwd) + '/results/'\n",
    "counter = 0\n",
    "for i in session_swaps:\n",
    "    swaps=i[:][:][:]\n",
    "    meanswaps=np.mean(swaps,axis=2)\n",
    "    mdic = {\"meanswaps\": meanswaps}\n",
    "    sio.savemat(data_dir + 'stroke_meanswaps' + str(counter) + '.mat', mdic)\n",
    "    counter = counter +1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
