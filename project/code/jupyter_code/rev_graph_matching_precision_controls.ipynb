{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, run the code in extract_precision_matrices.ipynb to obtain precision matrices: FCprec_concat_allsub.mat\n",
    "# which is a .mat file with all subjects' precision FC matrices (C) in the format k*n*n where k = num subjects and n = number of ROIs\n",
    "\n",
    "# Run unpack_precision_mats to split FCprec_concat_allsub.mat into single subject .mat files\n",
    "\n",
    "cwd='/Users/emilyolafson/GIT/stroke-graph-matching/data/'\n",
    "unpack_precision_mats(cwd)\n",
    "\n",
    "# After unpack_precision_mats is run, format precision data:\n",
    "# - Set diagonals of precision FC to 0.\n",
    "# - create a .mat file that contains precision FCs in a cell array for input to graph matching. In this case,\n",
    "# subjects in rows & longitudinal time points is in columns.\n",
    "\n",
    "# MATLAB code for formatting this dataset: format_precision.m\n",
    "\n",
    "# then run code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = '/Users/emilyolafson/GIT/stroke-graph-matching/data'\n",
    "fc_dir =data_dir + '/controls/precision'\n",
    "fc=sio.loadmat(fc_dir + '/C_precision.mat')\n",
    "fc=fc['C_precision']\n",
    "intervals=[[0, 1], [1, 2], [2, 3], [3, 4]] #time point comparisons. 0=1, 1=2, etc.\n",
    "alphacounter=0\n",
    "betacounter=0\n",
    "session_swaps=list()\n",
    "for i in range(0, 4):\n",
    "    run_graph_matching_reg(intervals[i], fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_precision_mats(cwd):\n",
    "    \"\"\"Turn concatenated precision FC matrix into multiple single subject/single session matrices.\n",
    "    Save each single suject to /precision/ folder.\"\"\"\n",
    "    data_dir = str(cwd) \n",
    "    subj_all = np.genfromtxt(data_dir + 'controls/precision/subjects_ctl.txt', dtype = 'str') #list of subjects in same order as precision matrices are saved.    \n",
    "    fc_dir = data_dir + 'controls/precision/'\n",
    "    output_prec = sio.loadmat(fc_dir + 'FCprec_concat_allsub.mat')\n",
    "    prec = output_prec['C'] \n",
    "    c = 0\n",
    "    for sub in subj_all:\n",
    "        mdic = {\"C\": prec[c]}\n",
    "        sio.savemat(fc_dir + sub, mdic)\n",
    "        c=c+1\n",
    "        \n",
    "def remap_cost_regularized(interval, fc):\n",
    "    \"\"\"Cost function: the cost of remapping each node in matrix A to every other node in matrix B. \n",
    "    Output is fed into graph matching algorithm.\"\"\"\n",
    "    \n",
    "    cwd = os.getcwd()\n",
    "    data_dir = '/Users/emilyolafson/GIT/stroke-graph-matching/data'\n",
    "    distances=sio.loadmat(data_dir + '/pairwise_eucl_dist_shen268.mat')\n",
    "\n",
    "    distances=distances['eucl_dist']\n",
    "    costmat_all=list()\n",
    "\n",
    "    nROIs=fc[0][0].shape[0]\n",
    "    \n",
    "    #calculate cost between all ROIs\n",
    "    for i in range(0,fc.shape[0]): #subject \n",
    "\n",
    "            \n",
    "        costmat=np.zeros((nROIs,nROIs))\n",
    "\n",
    "        for x in range(0,nROIs): #x = time point 1.\n",
    "            a=fc[i,interval[0]][x]\n",
    "\n",
    "            for y in range(0,nROIs): #y = time point 2.\n",
    "                b=fc[i,interval[1]][y]\n",
    "                \n",
    "                costmat[x,y]=distance.euclidean(a,b)\n",
    "                \n",
    "        costmat_all.append(costmat)\n",
    "\n",
    "    return [costmat_all, nROIs]\n",
    "\n",
    "def graph_matching_regularized(costmat_all, interval, nROIs):\n",
    "    \"\"\"Runs graph matching w/ the Hungarian algorithm and saves outputs:\n",
    "    \n",
    "        cols_SXSY.txt - each row is a different subject. Values in each column represent the node\n",
    "        in the latter time point that the node in the prior time point was mapped to.\n",
    "        \n",
    "        roichanges_SXSY.txt - each row is a different subject. Values in each column represent \n",
    "        whether the node was remapped to a DIFFERENT node than itself in the subsequent time point \n",
    "        (elements are 0 or 1, 1 if the node was remapped to a different node and 0 if the node was mapped to itself.\n",
    "        Used to calculate remap frequency for each region, when averaged vertically (across subjects).\"\"\"\n",
    "    \n",
    "    results_dir = '/Users/emilyolafson/GIT/stroke-graph-matching/project/results/controls'\n",
    "    print(alphacounter)\n",
    "    nROIs=fc[0][0].shape[0]\n",
    "    nsubs=len(costmat_all) #test\n",
    "    \n",
    "    rows=np.zeros((nsubs,nROIs))\n",
    "    cols=np.zeros((nsubs,nROIs))\n",
    "    roichanges=np.zeros((nsubs,nROIs))\n",
    "    truecols=range(0,nROIs)\n",
    "\n",
    "    for i in range(0, nsubs):\n",
    "        cost=costmat_all[i]\n",
    "        rowind, colind=linear_sum_assignment(cost*10000) #graph matching part.\n",
    "        rows[i]=rowind\n",
    "        cols[i]=colind\n",
    "\n",
    "    np.savetxt(results_dir+'/precision/cols_'+ 'S'+str(interval[0]+1)+'S'+ str(interval[1]+1)+'_alpha' + str(alphacounter)+'_beta' + str(betacounter) + '.txt', cols)\n",
    "\n",
    "    for j in range(0,nsubs):\n",
    "        for i in range(0,nROIs):\n",
    "            if cols[j][i]!=truecols[i]:\n",
    "                roichanges[j][i]=1 #indices that are switched\n",
    "\n",
    "    allchanges=np.mean(roichanges,0)\n",
    "    np.savetxt(results_dir +'/precision/roichanges_' + 'S'+str(interval[0]+1)+'S'+ str(interval[1]+1) +'_alpha' + str(alphacounter)+'_beta' + str(betacounter) +'.txt', allchanges)\n",
    "    return [allchanges]\n",
    "\n",
    "def run_graph_matching_reg(interval, fc):\n",
    "    \"\"\"Calculate the cost of remapping across all subjects, and perform graph matching.\n",
    "    Saves outputs to /results/jupyter/.../stroke and /controls.\"\"\"\n",
    "    [costmat_all, nROIs]=remap_cost_regularized(interval, fc)\n",
    "    nswaps=graph_matching_regularized(costmat_all, interval, nROIs)\n",
    "    return nswaps, costmat_all\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
