{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial import distance\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/Users/emilyolafson/GIT/stroke-graph-matching/results/jupyter/linear_corr/control/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f1c36404f075>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/data'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/results/jupyter/linear_corr/control/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/results/jupyter/linear_corr/stroke/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/Users/emilyolafson/GIT/stroke-graph-matching/results/jupyter/linear_corr/control/'"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "data_dir = str(cwd) + '/data'\n",
    "path = str(cwd) + '/results/jupyter/linear_corr/control/'\n",
    "os.mkdir(path)\n",
    "path = str(cwd) + '/results/jupyter/linear_corr/stroke/'\n",
    "os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run all functions from here.\n",
    "\n",
    "# At this point, run merge_precision_mats.m to create separate matrices based on\n",
    "# diagnosis that are also arranged by subject/sesion (save to /precision/stroke and /precision/controls)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = str(cwd) + '/data'\n",
    "fc_dir =data_dir + '/pearson_fc/'\n",
    "subtype=['stroke', 'control']\n",
    "\n",
    "for dx in subtype:\n",
    "    fc=sio.loadmat(fc_dir + dx + '/C_linearfc.mat')\n",
    "\n",
    "    fc=fc['C_linearfc']\n",
    "    intervals=[[0, 1], [1, 2], [2, 3], [3, 4]] #time point comparisons. 0=1, 1=2, etc.\n",
    " \n",
    "    for i in range(0, 4):\n",
    "        run_graph_matching(intervals[i], fc, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_cost(interval, fc):\n",
    "    \"\"\"Cost function: the cost of remapping each node in matrix A to every other node in matrix B. \n",
    "        Output is fed into graph matching algorithm\"\"\"\n",
    "    costmat_all=list()\n",
    "\n",
    "    nROIs=fc[0][0].shape[0]\n",
    "    #calculate cost between all ROIs\n",
    "    for i in range(0,fc.shape[0]): #subject \n",
    "        if (dx == 'stroke' and i==5 and interval == [3,4]): #sub6 has no 4,5\n",
    "            continue\n",
    "        if (dx == 'stroke' and i==11 and (interval == [3,4] or interval == [2,3])): #sub12 has no 4,5 OR 3,4\n",
    "            continue\n",
    "        if (dx == 'stroke' and i==19 and (interval == [3,4] or interval == [2,3] or interval == [1,2])): #sub20 has no 4,5 OR 3,4 OR 2,3\n",
    "            continue\n",
    "        costmat=np.zeros((nROIs,nROIs))\n",
    "        fc[i,interval[0]][np.eye(nROIs, dtype=bool)]=0\n",
    "        for x in range(0,nROIs): #x = time point 1.\n",
    "            a=fc[i,interval[0]][x]\n",
    "            for y in range(0,nROIs): #y = time point 2.\n",
    "                b=fc[i,interval[1]][y]\n",
    "                costmat[x,y]=distance.euclidean(a,b)\n",
    "        costmat_all.append(costmat)\n",
    "        \n",
    "    return [costmat_all, nROIs]\n",
    "\n",
    "\n",
    "def graph_matching(costmat_all, interval, nROIs, dx):\n",
    "    \"\"\"Runs graph matching w/ the Hungarian algorithm and saves outputs:\n",
    "    \n",
    "        cols_SXSY.txt - each row is a different subject. Values in each column represent the node\n",
    "        in the latter time point that the node in the prior time point was mapped to.\n",
    "        \n",
    "        roichanges_SXSY.txt - each row is a different subject. Values in each column represent \n",
    "        whether the node was remapped to a DIFFERENT node than itself in the subsequent time point \n",
    "        (elements are 0 or 1, 1 if the node was remapped to a different node and 0 if the node was mapped to itself.\n",
    "        Used to calculate remap frequency for each region, when averaged vertically (across subjects).\"\"\"\n",
    "    \n",
    "    results_dir = str(cwd) + '/results/jupyter/precision/'\n",
    "\n",
    "    nROIs=fc[0][0].shape[0]\n",
    "    nsubs=len(costmat_all) #test\n",
    "    \n",
    "    rows=np.zeros((nsubs,nROIs))\n",
    "    cols=np.zeros((nsubs,nROIs))\n",
    "    roichanges=np.zeros((nsubs,nROIs))\n",
    "    truecols=range(0,nROIs)\n",
    "\n",
    "    for i in range(0, nsubs):\n",
    "        cost=costmat_all[i]\n",
    "        rowind, colind=linear_sum_assignment(cost) #graph matching part.\n",
    "        rows[i]=rowind\n",
    "        cols[i]=colind\n",
    "\n",
    "    np.savetxt(results_dir+ dx +'/cols_'+ 'S'+str(interval[0]+1)+'S'+ str(interval[1]+1)+'.txt', cols)\n",
    "\n",
    "    for j in range(0,nsubs):\n",
    "        for i in range(0,nROIs):\n",
    "            if cols[j][i]!=truecols[i]:\n",
    "                roichanges[j][i]=1 #indices that are switched\n",
    "\n",
    "    allchanges=np.mean(roichanges,0)\n",
    "    np.savetxt(results_dir + dx +'/roichanges_' + 'S'+str(interval[0]+1)+'S'+ str(interval[1]+1) +'.txt', allchanges)\n",
    "\n",
    "def unpack_precision_mats():\n",
    "    \"\"\"Turn concatenated precision FC matrix into multiple single subject/single session matrices.\n",
    "    Save to /precision/ folder.\"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    data_dir = str(cwd) + '/data/'\n",
    "    \n",
    "    subj_all = np.genfromtxt(data_dir + 'subjects.txt', dtype = 'str') #list of subjects in same order as precision matrices are saved.    \n",
    "    fc_dir = data_dir + '/precision/'\n",
    "    output_prec = sio.loadmat(fc_dir + 'FCprec_concat_allsub.mat')\n",
    "    prec = output_prec['C'] \n",
    "    c = 0\n",
    "    for sub in subj_all:\n",
    "        mdic = {\"C\": prec[c]}\n",
    "        sio.savemat(fc_dir + sub, mdic)\n",
    "\n",
    "def run_graph_matching(interval, fc, dx):\n",
    "    \"\"\"Calculate the cost of remapping across all subjects, and perform graph matching.\n",
    "    Saves outputs to /results/jupyter/.../stroke and /controls.\"\"\"\n",
    "    [costmat_all, nROIs]=remap_cost(interval, fc)\n",
    "    graph_matching(costmat_all, interval, nROIs, dx)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_font = {'fontname':'Arial', 'size':'16', 'color':'black', 'weight':'normal',\n",
    " #             'verticalalignment':'bottom'} # Bottom vertical alignment for more space\n",
    "#axis_font = {'fontname':'Arial', 'size':'14'}\n",
    "\n",
    "\n",
    "#fig = plt.figure(figsize=(10, 10))\n",
    "#plt.ylabel(\"Session 2 FC nodes\", **axis_font)\n",
    "#plt.xlabel(\"Session 1 FC nodes\", **axis_font)\n",
    "#plt.title(\"Cost matrix\", **title_font)\n",
    "\n",
    "#plotting.plot_matrix(allsubs_nopenalty_S2S3[13], figure=fig)\n",
    "#plotting.plot_matrix(costmat_all[8], figure=fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
